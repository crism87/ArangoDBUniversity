{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "FuzzySearch.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfxiSjWR8Kmw",
        "colab_type": "text"
      },
      "source": [
        "![arangodb](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/ArangoDB_logo.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE3KR8sW8Kmw",
        "colab_type": "text"
      },
      "source": [
        "# Fuzzy Search "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3DiEFJE8Kmx",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joerg84/ArangoDBUniversity/blob/master/FuzzySearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o7Vn4Uo8Kmy",
        "colab_type": "text"
      },
      "source": [
        "ArangoSearch provides information retrieval features, natively integrated into ArangoDB’s query language and with support for all data models. It is primarily a full-text search engine, a much more powerful alternative to the full-text index type.\n",
        "Check this [ArangoSearch notebook](https://colab.research.google.com/github/joerg84/ArangoDBUniversity/blob/master/ArangoSearch.ipynb) for an introduction to ArangoSearch.\n",
        "\n",
        "When dealing with real-world text retrieval, we often not only care about exact matches to our search phrase but need to consider for example typos or alternative spellings.\n",
        "“Fuzzy search” is an umbrella term referring to a set of algorithms for such approximate matching. Usually such algorithms evaluate some similarity measure showing how close a search term is to the items in a dictionary. Then a search engine can make a decision on which results have to be shown first.\n",
        "\n",
        "In this notebook we will apply at two different implementation of fuzzy search in [ArangoSearch](https://www.arangodb.com/why-arangodb/full-text-search-engine-arangosearch/):\n",
        "* [Levenshtein distance](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#levenshtein_match\n",
        ")\n",
        "* [NGram similarity](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlcbVfOs8Kmy",
        "colab_type": "text"
      },
      "source": [
        "# Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoIFBPwp8Kmy",
        "colab_type": "text"
      },
      "source": [
        "Before getting started with ArangoSearch we need to prepare our environment and create a temporary database on ArangoDB's managed Service Oasis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXdL1FZe8Kmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/joerg84/ArangoDBUniversity.git\n",
        "!rsync -av ArangoDBUniversity/ ./ --exclude=.git\n",
        "!pip3 install pyarango\n",
        "!pip3 install \"python-arango>=5.0\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pKXjdTS8Km2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import sys\n",
        "import oasis\n",
        "import time\n",
        "\n",
        "from pyArango.connection import *\n",
        "from arango import ArangoClient"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6968hvSs8Km3",
        "colab_type": "text"
      },
      "source": [
        "Create the temporary database:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaGHLin28Km4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "21dc604e-b9cf-4ca2-e4b7-7f254315ef01"
      },
      "source": [
        "# Retrieve tmp credentials from ArangoDB Tutorial Service\n",
        "login = oasis.getTempCredentials(tutorialName=\"ArangoSearchIMDBTutorial\", credentialProvider=\"https://d383fa0b596a.arangodb.cloud:8529/_db/_system/tutorialDB/tutorialDB\")\n",
        "\n",
        "# Connect to the temp database\n",
        "# Please note that we use the python-arango driver as it has better support for ArangoSearch \n",
        "database = oasis.connect_python_arango(login)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requesting new temp credentials.\n",
            "Temp database ready to use.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECAfpWU48Km6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "19326a01-1bc8-484b-ccfe-d6a7d59c383a"
      },
      "source": [
        "print(\"https://\"+login[\"hostname\"]+\":\"+str(login[\"port\"]))\n",
        "print(\"Username: \" + login[\"username\"])\n",
        "print(\"Password: \" + login[\"password\"])\n",
        "print(\"Database: \" + login[\"dbName\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://d383fa0b596a.arangodb.cloud:8529\n",
            "Username: TUT3wlz5tr4w4aetcuylucetk\n",
            "Password: TUT1k1fer0o2ld0ytakem8m08e\n",
            "Database: TUTza6c80ni8cjraqxvvr6web\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ0mydlq8Km8",
        "colab_type": "text"
      },
      "source": [
        "Feel free to use to above URL to checkout the WebUI!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vXqUK6L8Km9",
        "colab_type": "text"
      },
      "source": [
        "##  IMDB Example Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9JQShDi8Km9",
        "colab_type": "text"
      },
      "source": [
        "![imdb](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/IMDB_graph.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXkaey-g8Km9",
        "colab_type": "text"
      },
      "source": [
        "Last, but not least we will import the [IMBD Example Dataset](https://github.com/arangodb/example-datasets/tree/master/Graphs/IMDB) including information about various movies, actors, directors, ... as a graph. \n",
        "*Note the included arangorestore will only work on Linux or Windows systems, if you want to run this notebook on a different OS please consider using the appropriate arangorestore from the [Download area](https://www.arangodb.com/download-major/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKM6jcXa8Km-",
        "colab_type": "text"
      },
      "source": [
        "## Linux:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPqigG8H8Km-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "0bc52ca3-df07-4d61-d87c-4c7b5cb363b9"
      },
      "source": [
        "! ./tools/arangorestore -c none --server.endpoint http+ssl://{login[\"hostname\"]}:{login[\"port\"]} --server.username {login[\"username\"]} --server.database {login[\"dbName\"]} --server.password {login[\"password\"]} --default-replication-factor 3  --input-directory \"data/imdb\""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m2020-06-17T18:25:16Z [436] INFO [05c30] {restore} Connected to ArangoDB 'http+ssl://d383fa0b596a.arangodb.cloud:8529'\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:16Z [436] INFO [3b6a4] {restore} no properties object\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:16Z [436] INFO [9b414] {restore} # Re-creating document collection 'imdb_vertices'...\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:16Z [436] INFO [9b414] {restore} # Re-creating edge collection 'imdb_edges'...\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:17Z [436] INFO [6d69f] {restore} # Dispatched 2 job(s), using 2 worker(s)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:17Z [436] INFO [d88c6] {restore} # Creating indexes for collection 'imdb_vertices'...\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:17Z [436] INFO [94913] {restore} # Loading data into edge collection 'imdb_edges', data size: 48957903 byte(s)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:17Z [436] INFO [94913] {restore} # Loading data into document collection 'imdb_vertices', data size: 22665786 byte(s)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:22Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 16777216 byte(s) from datafiles, sent 2 data batch(es) of 0 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:27Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 16777216 byte(s) from datafiles, sent 2 data batch(es) of 0 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:32Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 25165824 byte(s) from datafiles, sent 3 data batch(es) of 8388598 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:37Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 33554432 byte(s) from datafiles, sent 4 data batch(es) of 16777139 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:38Z [436] INFO [69a73] {restore} # Still loading data into edge collection 'imdb_edges', 16777216 of 48957903 byte(s) restored (34 %)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:42Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 41943040 byte(s) from datafiles, sent 5 data batch(es) of 25165735 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:47Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 41943040 byte(s) from datafiles, sent 5 data batch(es) of 25165735 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:51Z [436] INFO [69a73] {restore} # Still loading data into document collection 'imdb_vertices', 16777216 of 22665786 byte(s) restored (74 %)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:52Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 47831610 byte(s) from datafiles, sent 6 data batch(es) of 33554336 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:25:57Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 41942766 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:02Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 41942766 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:07Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 41942766 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:12Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 41942766 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:17Z [436] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 41942766 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:17Z [436] INFO [6ae09] {restore} # Successfully restored document collection 'imdb_vertices'\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:19Z [436] INFO [69a73] {restore} # Still loading data into edge collection 'imdb_edges', 33554432 of 48957903 byte(s) restored (68 %)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:22Z [436] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 64608826 byte(s) from datafiles, sent 8 data batch(es) of 56220084 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:27Z [436] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 64608826 byte(s) from datafiles, sent 8 data batch(es) of 56220084 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:32Z [436] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 71623689 byte(s) from datafiles, sent 9 data batch(es) of 64608683 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:37Z [436] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 71623689 byte(s) from datafiles, sent 9 data batch(es) of 64608683 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:39Z [436] INFO [69a73] {restore} # Still loading data into edge collection 'imdb_edges', 48957903 of 48957903 byte(s) restored (100 %)\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:39Z [436] INFO [6ae09] {restore} # Successfully restored edge collection 'imdb_edges'\n",
            "\u001b[0m\u001b[0m2020-06-17T18:26:39Z [436] INFO [a66e1] {restore} Processed 2 collection(s) in 83.140011 s, read 71623689 byte(s) from datafiles, sent 9 data batch(es) of 71623687 byte(s) total size\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yE_uMym8KnA",
        "colab_type": "text"
      },
      "source": [
        "# Create First View"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhQynyJJ8KnB",
        "colab_type": "text"
      },
      "source": [
        "As discussed above, an ArangoSearch view contains references to documents stored in different collections. \n",
        "This makes it possible to perform complex federated searches, even over a complete graph including vertex and edge collections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-koXo6C8KnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "4b34f5fb-7611-49e1-bcc4-d7b437a25410"
      },
      "source": [
        "# Create an ArangoSearch view.\n",
        "database.create_arangosearch_view(\n",
        "    name='v_imdb',\n",
        "    properties={'cleanupIntervalStep': 0}\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ViewCreateError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mViewCreateError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a842a155048b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m database.create_arangosearch_view(\n\u001b[1;32m      3\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'v_imdb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cleanupIntervalStep'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/database.py\u001b[0m in \u001b[0;36mcreate_arangosearch_view\u001b[0;34m(self, name, properties)\u001b[0m\n\u001b[1;32m   2198\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mViewCreateError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_arangosearch_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/api.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0municode\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/database.py\u001b[0m in \u001b[0;36mresponse_handler\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mformat_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2198\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mViewCreateError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mViewCreateError\u001b[0m: [HTTP 409][ERR 1207] duplicate view name 'v_imdb'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn3rKYKG8KnD",
        "colab_type": "text"
      },
      "source": [
        "Let us check it is actually there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5bwOthX8KnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "891168b5-39d5-437b-8e7d-af4e3faf92c3"
      },
      "source": [
        "print(database[\"v_imdb\"])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<StandardCollection v_imdb>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7RJtPcu8KnF",
        "colab_type": "text"
      },
      "source": [
        "As of now this view is empty, so we need to link it to a collection (i.e., imdb_vertices)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBTst5wNkyxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "89dc298b-62aa-4945-b456-1ec6922280cc"
      },
      "source": [
        "print(database.analyzers())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'name': 'text_zh', 'type': 'text', 'properties': {'locale': 'zh.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_sv', 'type': 'text', 'properties': {'locale': 'sv.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_en', 'type': 'text', 'properties': {'locale': 'en.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_ru', 'type': 'text', 'properties': {'locale': 'ru.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_fi', 'type': 'text', 'properties': {'locale': 'fi.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_no', 'type': 'text', 'properties': {'locale': 'no.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'identity', 'type': 'identity', 'properties': {}, 'revision': 0, 'features': ['norm', 'frequency']}, {'name': 'text_it', 'type': 'text', 'properties': {'locale': 'it.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_pt', 'type': 'text', 'properties': {'locale': 'pt.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_es', 'type': 'text', 'properties': {'locale': 'es.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_fr', 'type': 'text', 'properties': {'locale': 'fr.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_de', 'type': 'text', 'properties': {'locale': 'de.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}, {'name': 'text_nl', 'type': 'text', 'properties': {'locale': 'nl.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True}, 'revision': 0, 'features': ['position', 'norm', 'frequency']}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSfISdj8kpd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e164067e-6fb2-4e2d-e3f3-fd1d111b3216"
      },
      "source": [
        " # Retrieve list of analyzers.\n",
        "database.analyzers()\n",
        "database.delete_analyzer('test_analyzer', ignore_missing=True)\n",
        "\n",
        "database.create_analyzer(\n",
        "        name='test_analyzer',\n",
        "        analyzer_type='text',\n",
        "        properties={'locale': 'en.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True, 'edgeNgram' : { 'min': 3, 'max': 8, 'preserveOriginal': True }},\n",
        "        features=[\"frequency\",'norm','position']\n",
        "    )\n",
        "\n",
        "\n",
        "#  locale: \"en.utf-8\",\n",
        "# ........>   case: \"lower\",\n",
        "# ........>   accent: false,\n",
        "# ........>   stemming: false,\n",
        "# ........>   stopwords: []\n",
        "# ........> }, [\"frequency\",\"norm\",\"position\"])\n",
        "\n",
        "# # Create an analyzer.\n",
        "# database.create_analyzer(\n",
        "#     name='bigram1',\n",
        "#     analyzer_type='text',\n",
        "#     properties={},\n",
        "#     features=[\"frequency\",\"norm\",\"position\"]\n",
        "# )\n",
        "\n",
        "#\"edgeNgram\" : { \"min\": 3, \"max\": 8, \"preserveOriginal\": True }\n",
        " \n",
        "#  (\"text_edge_ngrams\", \"text\", {\n",
        "# ........>   edgeNgram: { min: 3, max: 8, preserveOriginal: true },\n",
        "# ........>   locale: \"en.utf-8\",\n",
        "# ........>   case: \"lower\",\n",
        "# ........>   accent: false,\n",
        "# ........>   stemming: false,\n",
        "# ........>   stopwords: [ \"the\" ]\n",
        "# ........> }, [\"frequency\",\"norm\",\"position\"])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'features': ['position', 'norm', 'frequency'],\n",
              " 'name': 'TUTza6c80ni8cjraqxvvr6web::test_analyzer',\n",
              " 'properties': {'accent': False,\n",
              "  'case': 'lower',\n",
              "  'edgeNgram': {'max': 8, 'min': 3, 'preserveOriginal': True},\n",
              "  'locale': 'en.utf-8',\n",
              "  'stemming': True,\n",
              "  'stopwords': []},\n",
              " 'revision': 13,\n",
              " 'type': 'text'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL8GQTtQ8KnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "f0d486c8-658d-4079-e4f6-5226705ce114"
      },
      "source": [
        " link = { \n",
        "  \"includeAllFields\": True,\n",
        "  \"fields\" : { \"description\" : { \"analyzers\" : [ \"test_analyzer\" ] } }\n",
        "}\n",
        "\n",
        "\n",
        "database.update_arangosearch_view(\n",
        "    name='v_imdb',\n",
        "    properties={'links': { 'imdb_vertices': link }}\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cleanup_interval_step': 0,\n",
              " 'commit_interval_msec': 1000,\n",
              " 'consolidation_interval_msec': 10000,\n",
              " 'consolidation_policy': {'min_score': 0,\n",
              "  'segments_bytes_floor': 2097152,\n",
              "  'segments_bytes_max': 5368709120,\n",
              "  'segments_max': 10,\n",
              "  'segments_min': 1,\n",
              "  'type': 'tier'},\n",
              " 'global_id': 'c60023776/',\n",
              " 'id': '60023776',\n",
              " 'links': [{}],\n",
              " 'name': 'v_imdb',\n",
              " 'primary_sort': [],\n",
              " 'type': 'arangosearch',\n",
              " 'writebuffer_active': 0,\n",
              " 'writebuffer_idle': 64,\n",
              " 'writebuffer_max_size': 33554432}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMZumewz8KnH",
        "colab_type": "text"
      },
      "source": [
        "As the indexing might take a few seconds, let us have a brief look at what is actually going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Xus7i28KnI",
        "colab_type": "text"
      },
      "source": [
        "![ArangoSearch](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/ArangoSearch_Arch.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5XppaGr8KnI",
        "colab_type": "text"
      },
      "source": [
        "By now our view should be ready, so let us issue the first query and look for short Drama Movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6fIUV9N8KnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "34108b3a-403e-4133-8ba1-34994a1822bf"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "  FOR d IN v_imdb \n",
        "    SEARCH d.type == \"Movie\" \n",
        "    AND \n",
        "    d.genre == \"Drama\" \n",
        "    AND \n",
        "    d.runtime IN 10..50 \n",
        "    RETURN d.title\n",
        "  \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wellcome\n",
            "Rosemarie Nitribitt - Tod einer Edelhure\n",
            "Wiatr\n",
            "Primavera\n",
            "Lücken im Gedankenstrom\n",
            "Dr. Jekyll and Mr. Hyde\n",
            "Breaking Glass\n",
            "Pulsar\n",
            "Frühlings Erwachen - Eine Kindertragödie\n",
            "Glastage\n",
            "Sunday in August\n",
            "Land gewinnen\n",
            "À San Remo\n",
            "Carne\n",
            "Dr. Jekyll and Mr. Hyde\n",
            "Room 10\n",
            "Zwischen Flieder wandern und singen\n",
            "Alias\n",
            "Antoine et Colette\n",
            "Edison's Frankenstein\n",
            "Silvester Home Run\n",
            "Bis zur Unendlichkeit\n",
            "Space Riders\n",
            "True\n",
            "Kurz:Ivan\n",
            "Dreamcatcher\n",
            "The Kolaborator\n",
            "Rounds\n",
            "Melissa\n",
            "Hotel Chevalier\n",
            "Another Lady Innocent\n",
            "The Wiggles: Wiggle Bay\n",
            "Good Night\n",
            "Crin blanc: Le cheval sauvage\n",
            "VeggieTales: An Easter Carol\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF3oT3gQfbB0",
        "colab_type": "text"
      },
      "source": [
        "**NGram Match**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQlOtFJCfglL",
        "colab_type": "text"
      },
      "source": [
        "Let us start by using the NGram match to find mispelled movie title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9_f99xRfvcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "outputId": "3a01972d-b4c0-490a-e456-4396a6c35258"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "FOR d IN v_imdb SEARCH NGRAM_MATCH(d.title, 'Str War', 0.7, 'test_analyzer')\n",
        "SORT BM25(d) DESC\n",
        "RETURN d.title\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 0))\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AQLQueryExecuteError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAQLQueryExecuteError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-481afd4711af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSORT\u001b[0m \u001b[0mBM25\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mDESC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mRETURN\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \"\"\")\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Iterate through the result cursor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/aql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, count, batch_size, ttl, bind_vars, full_count, max_plans, optimizer_rules, cache, memory_limit, fail_on_warning, profile, max_transaction_size, max_warning_count, intermediate_commit_count, intermediate_commit_size, satellite_sync_wait, read_collections, write_collections, stream, skip_inaccessible_cols, max_runtime)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/api.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0municode\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/aql.py\u001b[0m in \u001b[0;36mresponse_handler\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAQLQueryExecuteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAQLQueryExecuteError\u001b[0m: [HTTP 400][ERR 10] AQL: Error message received from cluster node 'PRMR-zpamyasv': failed to build filter while querying arangosearch view, query '{\"type\":\"n-ary or\",\"typeID\":63,\"subNodes\":[{\"type\":\"n-ary and\",\"typeID\":62,\"subNodes\":[{\"type\":\"function call\",\"typeID\":47,\"name\":\"NGRAM_MATCH\",\"subNodes\":[{\"type\":\"array\",\"typeID\":41,\"subNodes\":[{\"type\":\"attribute access\",\"typeID\":35,\"name\":\"title\",\"subNodes\":[{\"type\":\"reference\",\"typeID\":45,\"name\":\"d\",\"id\":0}]},{\"type\":\"value\",\"typeID\":40,\"value\":\"Str War\",\"vType\":\"string\",\"vTypeID\":4},{\"type\":\"value\",\"typeID\":40,\"value\":0.7,\"vType\":\"double\",\"vTypeID\":3},{\"type\":\"value\",\"typeID\":40,\"value\":\"test_analyzer\",\"vType\":\"string\",\"vTypeID\":4}]}]}]}]}': '' AQL function: Unable to load requested analyzer 'test_analyzer' (while executing)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XsTF8Mtfwaj",
        "colab_type": "text"
      },
      "source": [
        "In this query we setup a typical FOR loop and iterate over the previously created view with stored values(stored values not required for Fuzzy search). Then we use the NGRAM_MATCH Search function to search the description of the movies in our view to find movies with similar results. The .7 is the threshold amount, this is how much ‘fuzziness’ or wiggle-room we want to give the search.\n",
        "\n",
        "The threshold indicates just how far from our supplied phrase the results should be allowed to go. The number must be between 0 and 1 and the closer to 1 you get the more accurate you are requesting the results to be. The next thing is the analyzer we are using and this deserves a little further explanation.\n",
        "\n",
        "This ngram analyzer was configured with a min and max of 2, which means it looks at words 2 letters at a time. This is useful for determining the longest common sequence and context. The idea behind n-gram matching is searching for similar words, but not necessarily exact matches. One of the simplest ways of calculating similarity between two words is calculating the longest common sequence (LCS) of letters. The longer the LCS is the more similar the words are. However, this approach has one big disadvantage – absence of context. For example, words <connection> and <fonetica> have a long LCS (o-n-e-t-i) but very different meanings. To add some context, ngram sequences are used.\n",
        "\n",
        "Each word is split into a series of letter groups and these groups are then matched. If we use the same words, but calculate similarity based on 3-grams, an ngram with max and min of 3, we will get a better similarity measure: con-onn-nne-nec-ect-cti-tio-ion vs. fon-one-net-eti-tic-ica gives shorter LCS ( zero matches). To get rid of length differences we normalize the LCS length by word length. We calculate these matches to get a rating with a value between 0 (no match at all) and 1(fully matched). The ability to use this rating generated with ngrams is implemented in ArangoSearch with the NGRAM_MATCH function.\n",
        "\n",
        "This functionality is why we are still able to get relevant results even with misspelled words:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vUgcAWSpdl8l"
      },
      "source": [
        "**bold text**## Levenshtein MATCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JisqzP5dflN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr-gqDa8de1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn4WyyHN8KnL",
        "colab_type": "text"
      },
      "source": [
        "Proximity searching is a way to search for two or more words that occur within a certain number of words from each other.\n",
        "In the next example, we are looking for the word sequence \"in <any word> galaxy\" in the description of a movie.\n",
        "Feel free to try other values!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MExWiwZV8KnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute the query\n",
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "  FOR d IN v_imdb \n",
        "  SEARCH PHRASE(\n",
        "    d.description, \n",
        "    \"in\", \n",
        "    1, \n",
        "    \"galaxy\", \n",
        "    \"text_en\"\n",
        "    ) \n",
        "    RETURN {\n",
        "      title: d.title, \n",
        "      description: d.description\n",
        "      }\n",
        "  \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYzxDnGn8KnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute the query\n",
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "  FOR doc IN v_imdb\n",
        "    SEARCH NGRAM_MATCH(\n",
        "      doc.description, \n",
        "      'galaxy', \n",
        "      'text_en'\n",
        "      )\n",
        "    RETURN doc\n",
        "  \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_odf-YL8KnP",
        "colab_type": "text"
      },
      "source": [
        "## Ranking and Document Relevance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r28jaPHQ8KnQ",
        "colab_type": "text"
      },
      "source": [
        "Great, now we can identify documents containing a specific phrase,\n",
        "but especially with large document bases we need to be able to rank documents based on the their relevance.\n",
        "ArangoSearch supports the following two schemes:\n",
        "\n",
        "* [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)\n",
        "\n",
        "* [TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
        "\n",
        "You can learn more about ranking in the [documentation](https://www.arangodb.com/docs/3.6/aql/functions-arangosearch.html#scoring-functions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaHKlz4i8KnQ",
        "colab_type": "text"
      },
      "source": [
        "So let us find movies with the following key-words: “amazing, action, world, alien, sci-fi, science, documental, galaxy”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X--MngEQ8KnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "  FOR d IN v_imdb \n",
        "    SEARCH ANALYZER(\n",
        "      d.description \n",
        "      IN TOKENS('amazing action world alien sci-fi science documental galaxy', \n",
        "      'text_en'), \n",
        "      'text_en'\n",
        "      ) \n",
        "    SORT BM25(d) DESC \n",
        "    LIMIT 10 \n",
        "    RETURN {\n",
        "      \"title\": d.title, \n",
        "      \"description\" : d.description\n",
        "      }\n",
        "    \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO8ML2uL8KnS",
        "colab_type": "text"
      },
      "source": [
        "Another crucial point of ArangoSearch is the ability to fine-tune document scores evaluated by relevance models at query time. That functionality is exposed in AQL via the BOOST function.\n",
        "So let us tweak our previous query to prefer “galaxy” amongst the others keywords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a700mbyw8KnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "  FOR d IN v_imdb \n",
        "    SEARCH ANALYZER(\n",
        "      d.description \n",
        "      IN TOKENS('amazing action world alien sci-fi science documental', \n",
        "      'text_en'\n",
        "      ) \n",
        "    ||\n",
        "    BOOST(\n",
        "      d.description \n",
        "      IN TOKENS('galaxy', \n",
        "      'text_en'), \n",
        "      5), \n",
        "      'text_en'\n",
        "      ) \n",
        "    SORT BM25(d) DESC \n",
        "    LIMIT 10 \n",
        "    RETURN {\n",
        "      \"title\": d.title, \n",
        "      \"description\" : d.description\n",
        "      }\n",
        "\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEH4TMs38KnU",
        "colab_type": "text"
      },
      "source": [
        "## ArangoSearch Meets Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZI9n9mq8KnU",
        "colab_type": "text"
      },
      "source": [
        "One of the coolest features of ArangoDB, being a multi-model database, is that we can combine different data-model and query capabilites.\n",
        "So, for example, we can easily combine ArangoSearch with a Graph traversal. Recall that our imdb dataset is a graph with edges connecting \n",
        "the movies we have been looking at to their respective actors, genres, or directors. Let us explore this and look up the director for each each of the Sci-fi movies above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4z6RdVy8KnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "FOR d IN v_imdb \n",
        "   SEARCH ANALYZER(\n",
        "     d.description \n",
        "     IN TOKENS('amazing action world alien sci-fi science documental', \n",
        "     'text_en'\n",
        "     ) \n",
        "     ||\n",
        "   BOOST(\n",
        "     d.description \n",
        "     IN TOKENS('galaxy', 'text_en'), \n",
        "     5), \n",
        "     'text_en'\n",
        "     ) \n",
        "     \n",
        "   SORT BM25(d) DESC \n",
        "\n",
        "   LIMIT 10 \n",
        "\n",
        "     FOR vertex, edge, path \n",
        "      IN 1..1 INBOUND  \n",
        "      d imdb_edges\n",
        "      FILTER path.edges[0].$label == \"DIRECTED\"\n",
        "      RETURN DISTINCT {\n",
        "        \"director\" : vertex.name, \n",
        "        \"movie\" : d.title\n",
        "        } \n",
        "\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWpH7oVb8KnW",
        "colab_type": "text"
      },
      "source": [
        "# Further Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP0KpLrK8KnW",
        "colab_type": "text"
      },
      "source": [
        "* https://www.arangodb.com/docs/stable/arangosearch.html\n",
        "\n",
        "* https://www.arangodb.com/arangodb-training-center/search/arangosearch/"
      ]
    }
  ]
}