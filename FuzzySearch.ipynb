{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "FuzzySearch.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfxiSjWR8Kmw",
        "colab_type": "text"
      },
      "source": [
        "![arangodb](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/ArangoDB_logo.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE3KR8sW8Kmw",
        "colab_type": "text"
      },
      "source": [
        "# Fuzzy Search "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3DiEFJE8Kmx",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joerg84/ArangoDBUniversity/blob/master/FuzzySearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o7Vn4Uo8Kmy",
        "colab_type": "text"
      },
      "source": [
        "ArangoSearch provides information retrieval features, natively integrated into ArangoDB’s query language and with support for all data models. It is primarily a full-text search engine, a much more powerful alternative to the full-text index type.\n",
        "Check this [ArangoSearch notebook](https://colab.research.google.com/github/joerg84/ArangoDBUniversity/blob/master/ArangoSearch.ipynb) for an introduction to ArangoSearch.\n",
        "\n",
        "When dealing with real-world text retrieval, we often not only care about exact matches to our search phrase but need to consider for example typos or alternative spellings.\n",
        "“Fuzzy search” is an umbrella term referring to a set of algorithms for such approximate matching. Usually such algorithms evaluate some similarity measure showing how close a search term is to the items in a dictionary. Then a search engine can make a decision on which results have to be shown first.\n",
        "\n",
        "In this notebook we will apply at two different implementation of fuzzy search in [ArangoSearch](https://www.arangodb.com/why-arangodb/full-text-search-engine-arangosearch/):\n",
        "* [Levenshtein distance](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#levenshtein_match\n",
        ")\n",
        "* [NGram similarity](https://www.arangodb.com/docs/devel/aql/functions-arangosearch.html#ngram_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlcbVfOs8Kmy",
        "colab_type": "text"
      },
      "source": [
        "# Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoIFBPwp8Kmy",
        "colab_type": "text"
      },
      "source": [
        "Before getting started with ArangoSearch we need to prepare our environment and create a temporary database on ArangoDB's managed Service Oasis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXdL1FZe8Kmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/joerg84/ArangoDBUniversity.git\n",
        "!rsync -av ArangoDBUniversity/ ./ --exclude=.git\n",
        "!pip3 install pyarango\n",
        "!pip3 install \"python-arango>=5.0\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pKXjdTS8Km2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import sys\n",
        "import oasis\n",
        "import time\n",
        "\n",
        "from pyArango.connection import *\n",
        "from arango import ArangoClient"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6968hvSs8Km3",
        "colab_type": "text"
      },
      "source": [
        "Create the temporary database:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaGHLin28Km4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d105841b-17b3-443a-f006-d640e97b33d5"
      },
      "source": [
        "# Retrieve tmp credentials from ArangoDB Tutorial Service\n",
        "login = oasis.getTempCredentials(tutorialName=\"FuzzyArangoSearch\", credentialProvider=\"https://d383fa0b596a.arangodb.cloud:8529/_db/_system/tutorialDB/tutorialDB\")\n",
        "\n",
        "# Connect to the temp database\n",
        "# Please note that we use the python-arango driver as it has better support for ArangoSearch \n",
        "database = oasis.connect_python_arango(login)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requesting new temp credentials.\n",
            "Temp database ready to use.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECAfpWU48Km6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d9c09e48-9bed-4732-e66d-5dd28ede3bc1"
      },
      "source": [
        "print(\"https://\"+login[\"hostname\"]+\":\"+str(login[\"port\"]))\n",
        "print(\"Username: \" + login[\"username\"])\n",
        "print(\"Password: \" + login[\"password\"])\n",
        "print(\"Database: \" + login[\"dbName\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://d383fa0b596a.arangodb.cloud:8529\n",
            "Username: TUT5f842cv13n85zbsat5n34\n",
            "Password: TUT408v9fa3ea3h19ti0r4f4g\n",
            "Database: TUTkvezj4ih96spxyap5skv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ0mydlq8Km8",
        "colab_type": "text"
      },
      "source": [
        "Feel free to use to above URL to checkout the WebUI!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vXqUK6L8Km9",
        "colab_type": "text"
      },
      "source": [
        "##  IMDB Example Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9JQShDi8Km9",
        "colab_type": "text"
      },
      "source": [
        "![imdb](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/IMDB_graph.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXkaey-g8Km9",
        "colab_type": "text"
      },
      "source": [
        "Last, but not least we will import the [IMBD Example Dataset](https://github.com/arangodb/example-datasets/tree/master/Graphs/IMDB) including information about various movies, actors, directors, ... as a graph. \n",
        "*Note the included arangorestore will only work on Linux or Windows systems, if you want to run this notebook on a different OS please consider using the appropriate arangorestore from the [Download area](https://www.arangodb.com/download-major/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKM6jcXa8Km-",
        "colab_type": "text"
      },
      "source": [
        "## Linux:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPqigG8H8Km-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "e89f439b-868a-4d17-f4bd-3517e6c4dd67"
      },
      "source": [
        "! ./tools/arangorestore -c none --server.endpoint http+ssl://{login[\"hostname\"]}:{login[\"port\"]} --server.username {login[\"username\"]} --server.database {login[\"dbName\"]} --server.password {login[\"password\"]} --default-replication-factor 3  --input-directory \"data/imdb\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m2020-07-07T20:29:59Z [183] INFO [05c30] {restore} Connected to ArangoDB 'http+ssl://d383fa0b596a.arangodb.cloud:8529'\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:00Z [183] INFO [3b6a4] {restore} no properties object\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:00Z [183] INFO [9b414] {restore} # Re-creating document collection 'imdb_vertices'...\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:00Z [183] INFO [9b414] {restore} # Re-creating edge collection 'imdb_edges'...\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:01Z [183] INFO [6d69f] {restore} # Dispatched 2 job(s), using 2 worker(s)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:01Z [183] INFO [d88c6] {restore} # Creating indexes for collection 'imdb_vertices'...\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:01Z [183] INFO [94913] {restore} # Loading data into edge collection 'imdb_edges', data size: 48957903 byte(s)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:01Z [183] INFO [94913] {restore} # Loading data into document collection 'imdb_vertices', data size: 22665786 byte(s)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:06Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 16777216 byte(s) from datafiles, sent 2 data batch(es) of 0 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:11Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 16777216 byte(s) from datafiles, sent 2 data batch(es) of 0 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:16Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 25165824 byte(s) from datafiles, sent 3 data batch(es) of 8388598 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:21Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 33554432 byte(s) from datafiles, sent 4 data batch(es) of 16777139 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:24Z [183] INFO [69a73] {restore} # Still loading data into edge collection 'imdb_edges', 16777216 of 48957903 byte(s) restored (34 %)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:26Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 41943040 byte(s) from datafiles, sent 5 data batch(es) of 25165735 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:30Z [183] INFO [69a73] {restore} # Still loading data into document collection 'imdb_vertices', 16777216 of 22665786 byte(s) restored (74 %)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:31Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 47831610 byte(s) from datafiles, sent 6 data batch(es) of 33554336 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:36Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 47831610 byte(s) from datafiles, sent 6 data batch(es) of 33554336 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:41Z [183] INFO [75e65] {restore} # Current restore progress: restored 0 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 41942766 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:44Z [183] INFO [6ae09] {restore} # Successfully restored document collection 'imdb_vertices'\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:46Z [183] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 56220218 byte(s) from datafiles, sent 7 data batch(es) of 47831409 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:47Z [183] INFO [69a73] {restore} # Still loading data into edge collection 'imdb_edges', 33554432 of 48957903 byte(s) restored (68 %)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:51Z [183] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 64608826 byte(s) from datafiles, sent 8 data batch(es) of 56220084 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:30:56Z [183] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 71623689 byte(s) from datafiles, sent 9 data batch(es) of 64608683 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:31:01Z [183] INFO [75e65] {restore} # Current restore progress: restored 1 of 2 collection(s), read 71623689 byte(s) from datafiles, sent 9 data batch(es) of 64608683 byte(s) total size, queued jobs: 0, workers: 2\n",
            "\u001b[0m\u001b[0m2020-07-07T20:31:02Z [183] INFO [69a73] {restore} # Still loading data into edge collection 'imdb_edges', 48957903 of 48957903 byte(s) restored (100 %)\n",
            "\u001b[0m\u001b[0m2020-07-07T20:31:02Z [183] INFO [6ae09] {restore} # Successfully restored edge collection 'imdb_edges'\n",
            "\u001b[0m\u001b[0m2020-07-07T20:31:02Z [183] INFO [a66e1] {restore} Processed 2 collection(s) in 64.481696 s, read 71623689 byte(s) from datafiles, sent 9 data batch(es) of 71623687 byte(s) total size\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yE_uMym8KnA",
        "colab_type": "text"
      },
      "source": [
        "# Create First View"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhQynyJJ8KnB",
        "colab_type": "text"
      },
      "source": [
        "As discussed above, an ArangoSearch view contains references to documents stored in different collections. \n",
        "This makes it possible to perform complex federated searches, even over a complete graph including vertex and edge collections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-koXo6C8KnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "ea20c3a1-782d-4bea-da42-f386771b540d"
      },
      "source": [
        "# Create an ArangoSearch view.\n",
        "database.create_arangosearch_view(\n",
        "    name='v_imdb',\n",
        "    properties={'cleanupIntervalStep': 0}\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cleanup_interval_step': 0,\n",
              " 'commit_interval_msec': 1000,\n",
              " 'consolidation_interval_msec': 10000,\n",
              " 'consolidation_policy': {'min_score': 0,\n",
              "  'segments_bytes_floor': 2097152,\n",
              "  'segments_bytes_max': 5368709120,\n",
              "  'segments_max': 10,\n",
              "  'segments_min': 1,\n",
              "  'type': 'tier'},\n",
              " 'global_id': 'c424087036/',\n",
              " 'id': '424087036',\n",
              " 'links': [],\n",
              " 'name': 'v_imdb',\n",
              " 'primary_sort': [],\n",
              " 'type': 'arangosearch',\n",
              " 'writebuffer_active': 0,\n",
              " 'writebuffer_idle': 64,\n",
              " 'writebuffer_max_size': 33554432}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn3rKYKG8KnD",
        "colab_type": "text"
      },
      "source": [
        "Let us check it is actually there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5bwOthX8KnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45bdc9cc-1473-4919-eac8-a986d55fdc97"
      },
      "source": [
        "print(database[\"v_imdb\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<StandardCollection v_imdb>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7RJtPcu8KnF",
        "colab_type": "text"
      },
      "source": [
        "As of now this view is empty, so we need to link it to a collection (i.e., imdb_vertices)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSfISdj8kpd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e164067e-6fb2-4e2d-e3f3-fd1d111b3216"
      },
      "source": [
        " # Retrieve list of analyzers.\n",
        "database.analyzers()\n",
        "\n",
        "# Delete test\n",
        "database.delete_analyzer('test_analyzer', ignore_missing=True)\n",
        "\n",
        "database.create_analyzer(\n",
        "        name='test_analyzer',\n",
        "        analyzer_type='text',\n",
        "        properties={'locale': 'en.utf-8', 'case': 'lower', 'stopwords': [], 'accent': False, 'stemming': True, 'edgeNgram' : { 'min': 3, 'max': 8, 'preserveOriginal': True }},\n",
        "        features=[\"frequency\",'norm','position']\n",
        "    )\n",
        "\n",
        "\n",
        "#  locale: \"en.utf-8\",\n",
        "# ........>   case: \"lower\",\n",
        "# ........>   accent: false,\n",
        "# ........>   stemming: false,\n",
        "# ........>   stopwords: []\n",
        "# ........> }, [\"frequency\",\"norm\",\"position\"])\n",
        "\n",
        "# # Create an analyzer.\n",
        "# database.create_analyzer(\n",
        "#     name='bigram1',\n",
        "#     analyzer_type='text',\n",
        "#     properties={},\n",
        "#     features=[\"frequency\",\"norm\",\"position\"]\n",
        "# )\n",
        "\n",
        "#\"edgeNgram\" : { \"min\": 3, \"max\": 8, \"preserveOriginal\": True }\n",
        " \n",
        "#  (\"text_edge_ngrams\", \"text\", {\n",
        "# ........>   edgeNgram: { min: 3, max: 8, preserveOriginal: true },\n",
        "# ........>   locale: \"en.utf-8\",\n",
        "# ........>   case: \"lower\",\n",
        "# ........>   accent: false,\n",
        "# ........>   stemming: false,\n",
        "# ........>   stopwords: [ \"the\" ]\n",
        "# ........> }, [\"frequency\",\"norm\",\"position\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'features': ['position', 'norm', 'frequency'],\n",
              " 'name': 'TUTza6c80ni8cjraqxvvr6web::test_analyzer',\n",
              " 'properties': {'accent': False,\n",
              "  'case': 'lower',\n",
              "  'edgeNgram': {'max': 8, 'min': 3, 'preserveOriginal': True},\n",
              "  'locale': 'en.utf-8',\n",
              "  'stemming': True,\n",
              "  'stopwords': []},\n",
              " 'revision': 13,\n",
              " 'type': 'text'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL8GQTtQ8KnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "f0d486c8-658d-4079-e4f6-5226705ce114"
      },
      "source": [
        " link = { \n",
        "  \"includeAllFields\": True,\n",
        "  \"fields\" : { \"description\" : { \"analyzers\" : [ \"test_analyzer\" ] } }\n",
        "}\n",
        "\n",
        "\n",
        "database.update_arangosearch_view(\n",
        "    name='v_imdb',\n",
        "    properties={'links': { 'imdb_vertices': link }}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cleanup_interval_step': 0,\n",
              " 'commit_interval_msec': 1000,\n",
              " 'consolidation_interval_msec': 10000,\n",
              " 'consolidation_policy': {'min_score': 0,\n",
              "  'segments_bytes_floor': 2097152,\n",
              "  'segments_bytes_max': 5368709120,\n",
              "  'segments_max': 10,\n",
              "  'segments_min': 1,\n",
              "  'type': 'tier'},\n",
              " 'global_id': 'c60023776/',\n",
              " 'id': '60023776',\n",
              " 'links': [{}],\n",
              " 'name': 'v_imdb',\n",
              " 'primary_sort': [],\n",
              " 'type': 'arangosearch',\n",
              " 'writebuffer_active': 0,\n",
              " 'writebuffer_idle': 64,\n",
              " 'writebuffer_max_size': 33554432}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMZumewz8KnH",
        "colab_type": "text"
      },
      "source": [
        "As the indexing might take a few seconds, let us have a brief look at what is actually going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Xus7i28KnI",
        "colab_type": "text"
      },
      "source": [
        "![ArangoSearch](https://github.com/joerg84/ArangoDBUniversity/blob/master/img/ArangoSearch_Arch.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5XppaGr8KnI",
        "colab_type": "text"
      },
      "source": [
        "By now our view should be ready, so let us issue the first query and look for short Drama Movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6fIUV9N8KnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "34108b3a-403e-4133-8ba1-34994a1822bf"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "  FOR d IN v_imdb \n",
        "    SEARCH d.type == \"Movie\" \n",
        "    AND \n",
        "    d.genre == \"Drama\" \n",
        "    AND \n",
        "    d.runtime IN 10..50 \n",
        "    RETURN d.title\n",
        "  \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wellcome\n",
            "Rosemarie Nitribitt - Tod einer Edelhure\n",
            "Wiatr\n",
            "Primavera\n",
            "Lücken im Gedankenstrom\n",
            "Dr. Jekyll and Mr. Hyde\n",
            "Breaking Glass\n",
            "Pulsar\n",
            "Frühlings Erwachen - Eine Kindertragödie\n",
            "Glastage\n",
            "Sunday in August\n",
            "Land gewinnen\n",
            "À San Remo\n",
            "Carne\n",
            "Dr. Jekyll and Mr. Hyde\n",
            "Room 10\n",
            "Zwischen Flieder wandern und singen\n",
            "Alias\n",
            "Antoine et Colette\n",
            "Edison's Frankenstein\n",
            "Silvester Home Run\n",
            "Bis zur Unendlichkeit\n",
            "Space Riders\n",
            "True\n",
            "Kurz:Ivan\n",
            "Dreamcatcher\n",
            "The Kolaborator\n",
            "Rounds\n",
            "Melissa\n",
            "Hotel Chevalier\n",
            "Another Lady Innocent\n",
            "The Wiggles: Wiggle Bay\n",
            "Good Night\n",
            "Crin blanc: Le cheval sauvage\n",
            "VeggieTales: An Easter Carol\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF3oT3gQfbB0",
        "colab_type": "text"
      },
      "source": [
        "**NGram Match**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haexui4sDce2",
        "colab_type": "text"
      },
      "source": [
        "Ngram similarity a measure for the difference between two strings represented by counting how long the longest sequence of matching ngrams is, divided by target’s total ngram count. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4-VhEhgC6oM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78eda087-0c25-4c93-bd22-213fbc2d59bf"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "RETURN NGRAM_SIMILARITY(\n",
        "\"quick fox\",\n",
        "\"quick foxx\", \n",
        "2)\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8888888955116272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWKNe-uiDhov",
        "colab_type": "text"
      },
      "source": [
        "With a ngram size of 2, the ngram similarity between both strings is 0.888. Feel free experiment with other combinations such as `NGRAM_SIMILARITY( \"same string\",\"same string\", 2)` or vary the ngramSize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQlOtFJCfglL",
        "colab_type": "text"
      },
      "source": [
        "Let us start by using the NGram match to find mispelled movie title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9_f99xRfvcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "outputId": "3a01972d-b4c0-490a-e456-4396a6c35258"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "FOR d IN v_imdb SEARCH NGRAM_MATCH(d.title, 'Str War', 0.7, 'test_analyzer')\n",
        "SORT BM25(d) DESC\n",
        "RETURN d.title\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:An unexpected error occurred while tokenizing input\n",
            "The following traceback may be corrupted or invalid\n",
            "The error message is: ('EOF in multi-line string', (1, 0))\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AQLQueryExecuteError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAQLQueryExecuteError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-481afd4711af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mSORT\u001b[0m \u001b[0mBM25\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mDESC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mRETURN\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \"\"\")\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Iterate through the result cursor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/aql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, count, batch_size, ttl, bind_vars, full_count, max_plans, optimizer_rules, cache, memory_limit, fail_on_warning, profile, max_transaction_size, max_warning_count, intermediate_commit_count, intermediate_commit_size, satellite_sync_wait, read_collections, write_collections, stream, skip_inaccessible_cols, max_runtime)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/api.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0municode\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[1;32m     81\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/arango/aql.py\u001b[0m in \u001b[0;36mresponse_handler\u001b[0;34m(resp)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAQLQueryExecuteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAQLQueryExecuteError\u001b[0m: [HTTP 400][ERR 10] AQL: Error message received from cluster node 'PRMR-zpamyasv': failed to build filter while querying arangosearch view, query '{\"type\":\"n-ary or\",\"typeID\":63,\"subNodes\":[{\"type\":\"n-ary and\",\"typeID\":62,\"subNodes\":[{\"type\":\"function call\",\"typeID\":47,\"name\":\"NGRAM_MATCH\",\"subNodes\":[{\"type\":\"array\",\"typeID\":41,\"subNodes\":[{\"type\":\"attribute access\",\"typeID\":35,\"name\":\"title\",\"subNodes\":[{\"type\":\"reference\",\"typeID\":45,\"name\":\"d\",\"id\":0}]},{\"type\":\"value\",\"typeID\":40,\"value\":\"Str War\",\"vType\":\"string\",\"vTypeID\":4},{\"type\":\"value\",\"typeID\":40,\"value\":0.7,\"vType\":\"double\",\"vTypeID\":3},{\"type\":\"value\",\"typeID\":40,\"value\":\"test_analyzer\",\"vType\":\"string\",\"vTypeID\":4}]}]}]}]}': '' AQL function: Unable to load requested analyzer 'test_analyzer' (while executing)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XsTF8Mtfwaj",
        "colab_type": "text"
      },
      "source": [
        "In this query we setup a typical FOR loop and iterate over the previously created view with stored values(stored values not required for Fuzzy search). Then we use the NGRAM_MATCH Search function to search the description of the movies in our view to find movies with similar results. The .7 is the threshold amount, this is how much ‘fuzziness’ or wiggle-room we want to give the search.\n",
        "\n",
        "The threshold indicates just how far from our supplied phrase the results should be allowed to go. The number must be between 0 and 1 and the closer to 1 you get the more accurate you are requesting the results to be. The next thing is the analyzer we are using and this deserves a little further explanation.\n",
        "\n",
        "This ngram analyzer was configured with a min and max of 2, which means it looks at words 2 letters at a time. This is useful for determining the longest common sequence and context. The idea behind n-gram matching is searching for similar words, but not necessarily exact matches. One of the simplest ways of calculating similarity between two words is calculating the longest common sequence (LCS) of letters. The longer the LCS is the more similar the words are. However, this approach has one big disadvantage – absence of context. For example, words <connection> and <fonetica> have a long LCS (o-n-e-t-i) but very different meanings. To add some context, ngram sequences are used.\n",
        "\n",
        "Each word is split into a series of letter groups and these groups are then matched. If we use the same words, but calculate similarity based on 3-grams, an ngram with max and min of 3, we will get a better similarity measure: con-onn-nne-nec-ect-cti-tio-ion vs. fon-one-net-eti-tic-ica gives shorter LCS ( zero matches). To get rid of length differences we normalize the LCS length by word length. We calculate these matches to get a rating with a value between 0 (no match at all) and 1(fully matched). The ability to use this rating generated with ngrams is implemented in ArangoSearch with the NGRAM_MATCH function.\n",
        "\n",
        "This functionality is why we are still able to get relevant results even with misspelled words:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQozIhflEv26",
        "colab_type": "text"
      },
      "source": [
        "While [NGRAM_SIMILARITY()](https://www.arangodb.com/docs/devel/aql/functions-string.html#ngram_similarity) only counts fully matching ngrams, [NGRAM_POSITIONAL_SIMILARITY()] (https://www.arangodb.com/docs/devel/aql/functions-string.html#ngram_positional_similarity) also considers partially matching ones. Let us look at how that effects the returned scores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z0Z9fXMEuPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbfeff36-9c1a-425c-b3ce-673c1f743926"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "RETURN\n",
        "{\"NGRAM_SIMILARITY\" : NGRAM_SIMILARITY(\n",
        "\"quick fox jumps\",\n",
        "\"quick foxx jups\", \n",
        "2),\n",
        "\"NGRAM_POSITIONAL_SIMILARITY\" : NGRAM_POSITIONAL_SIMILARITY(\n",
        "\"quick fox jumps\",\n",
        "\"quick foxx jups\", \n",
        "2)}\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NGRAM_SIMILARITY': 0.8571428656578064, 'NGRAM_POSITIONAL_SIMILARITY': 0.8928571343421936}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vUgcAWSpdl8l"
      },
      "source": [
        "## Levenshtein MATCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JisqzP5dflN",
        "colab_type": "text"
      },
      "source": [
        "[Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) is a measure for the difference between two strings represented by the  minimum number of single-character transformations required to move from one string to the other. Let is consider a concrete example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr-gqDa8de1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ec3b773-a313-43f8-8933-3fc774254a58"
      },
      "source": [
        "cursor = database.aql.execute(\n",
        "\"\"\"\n",
        "RETURN LEVENSHTEIN_DISTANCE(\n",
        "\"The quick brown fox jumps over the lazy dog\", \n",
        "\"The quick black dog jumps over the brown fox\")\"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r1uwBXLBaMk",
        "colab_type": "text"
      },
      "source": [
        "Here we need a minimum of 13 transformations to move from one string to the other. \n",
        "Feel free to find a minimum sequence for this transformation or experiment with other combinations such as `LEVENSHTEIN_DISTANCE(\"a\", \"b\")`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MExWiwZV8KnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute the query\n",
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "FOR d IN v_imdb SEARCH NGRAM_MATCH(d.title, 'Str War', 0.7, 'test_analyzer')\n",
        "SORT BM25(d) DESC\n",
        "RETURN d.title\n",
        "  \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYzxDnGn8KnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute the query\n",
        "cursor = database.aql.execute(\n",
        "  \"\"\"\n",
        "  FOR doc IN v_imdb\n",
        "    SEARCH NGRAM_MATCH(\n",
        "      doc.description, \n",
        "      'galaxy', \n",
        "      'text_en'\n",
        "      )\n",
        "    RETURN doc\n",
        "  \"\"\"\n",
        ")\n",
        "# Iterate through the result cursor\n",
        "for doc in cursor:\n",
        "  print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWpH7oVb8KnW",
        "colab_type": "text"
      },
      "source": [
        "# Further Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP0KpLrK8KnW",
        "colab_type": "text"
      },
      "source": [
        "* https://www.arangodb.com/docs/stable/arangosearch.html\n",
        "\n",
        "* https://www.arangodb.com/arangodb-training-center/search/arangosearch/"
      ]
    }
  ]
}